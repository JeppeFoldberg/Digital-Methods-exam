{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "317a88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils and general stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from exam_utils import timeParser\n",
    "import re\n",
    "\n",
    "#Packages to create DFM\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "#Models to train\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Packages for cross-validation and parameter tuning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9910fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('lemma_all.csv', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3406c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'tweet_created_at'] = df.tweet_created_at.apply(timeParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b626c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting only after the electiong and making a copy to get rid of the setting with copy warning\n",
    "df_ae = df.loc[df.tweet_created_at > '2019-06-05'].copy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a5c4b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ae.loc[:, 'tweet_id'] = df_ae.loc[:, 'tweet_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7027d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all retweets\n",
    "df_ae = df_ae.loc[~df_ae.tweet_full_text.str.contains('^RT')]\n",
    "\n",
    "# dropping nans in tweet lemma\n",
    "df_ae = df_ae.dropna(subset=['tweet_text_lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a0e55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(df, n=100, random_state=42):\n",
    "    '''Takes in a df and returns 100 random tweets to be labelled'''\n",
    "    temp = df.sample(n, random_state=random_state)\n",
    "    temp.loc[:, 'label'] = np.nan\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdd6c192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the first dataset to label!\n",
    "label = sample_dataset(df_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8d2ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label.to_excel('label_this.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692d6574",
   "metadata": {},
   "source": [
    "# Active learning loop\n",
    "\n",
    "## importing data and splitting into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e86c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(path, test_data=False):\n",
    "    '''takes in the path to the latest labelled data set and returns X_train, y_train, and a df\n",
    "    could have used train_test_split'''\n",
    "    new_df = pd.read_excel(path, index_col=0)\n",
    "    X = new_df.tweet_text_lemma\n",
    "    y = new_df.label\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    if test_data:\n",
    "        return X_train, X_test, y_train, y_test, new_df\n",
    "    else:\n",
    "        return X, y, new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f338be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelled_unlabelled(new_df, old_df):\n",
    "    '''takes in the new df and removes the ones in the new one from the old one'''\n",
    "    unlabelled_df = old_df.loc[~old_df.index.isin(new_df.index)]\n",
    "    return unlabelled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5fdce3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, labelled_df = split_data('label5.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e1718fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_df = labelled_unlabelled(labelled_df, df_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bca68945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline to train on\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "pipeline = Pipeline([ \n",
    "    ('cv', CountVectorizer(tokenizer=tokenizer.tokenize, ngram_range = (1, 2), max_df=0.999, min_df=0.01)),\n",
    "    ('tfidf', TfidfTransformer(use_idf = False)),\n",
    "    ('logreg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88e61966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv',\n",
       "                 CountVectorizer(max_df=0.999, min_df=0.01, ngram_range=(1, 2),\n",
       "                                 tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7fefe80bf0d0>>)),\n",
       "                ('tfidf', TfidfTransformer(use_idf=False)),\n",
       "                ('logreg', LogisticRegression())])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6ab0c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_unlabelled(pipeline, unlabelled_df):\n",
    "    '''takes in a pipeline, the unlabelled df and adds the maximum probability column\n",
    "    Then it sorts the dataframe by max proba and returns it'''\n",
    "    # predicts for the three classes for all entries in the dataset\n",
    "    predictions = pipeline.predict_proba(unlabelled_df.tweet_text_lemma)\n",
    "    # creates a column with the max probability\n",
    "    temp = unlabelled_df.copy()\n",
    "    temp.loc[:, 'max_proba'] = [max(pred) for pred in predictions]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "217e4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_df = predict_unlabelled(pipeline, unlabelled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f10a7aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7636363636363637"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a31e3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_new_set(unlabelled_df, labelled_df, new_name):\n",
    "    '''takes in the df produced above, sorts it and saves a new df to be labelled'''\n",
    "    unlabelled_df.sort_values(by='max_proba', inplace=True)\n",
    "    new_df = unlabelled_df[:100].copy()\n",
    "    new_df.loc[:, 'label'] = np.nan\n",
    "    new_df = pd.concat([new_df, labelled_df])\n",
    "    new_df.to_excel(f'{new_name}.xlsx')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "febfea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_new_set(unlabelled_df, labelled_df, 'label6')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04431cc6",
   "metadata": {},
   "source": [
    "## Checking the current score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5629a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in the parameter values in the grid \n",
    "parameter_grid = {\n",
    "    'tfidf__use_idf': [False, True],\n",
    "    'logreg__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'logreg__C': [0.1, 0.5, 1],\n",
    "}\n",
    "\n",
    "#Initializing a kfold with 5 folds\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "#Initializing the GridSearchCV\n",
    "search = GridSearchCV(pipeline, parameter_grid, cv=cv, n_jobs = -1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d16211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a59c127b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.778"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65cb9d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7577e145",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18fb54bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[209   3   0   3]\n",
      " [ 51  75   1   5]\n",
      " [ 35   6  36   1]\n",
      " [  5   0   1  69]]\n"
     ]
    }
   ],
   "source": [
    "print(conf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
