{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from app_cred import CONSUMER_KEY, CONSUMER_SECRET #import user specific keys to access twitter\n",
    "from app_cred import ACCESS_TOKEN, ACCESS_TOKEN_SECRET #import user specific keys to access twitter \n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True, \n",
    "                 wait_on_rate_limit_notify = True, \n",
    "                 timeout=900)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into four parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# handles=pd.read_excel(\"Initial network.xlsx\")\n",
    "# handles=handles[\"Twitter Handle (uden @)\"]\n",
    "# handle1, handle2, handle3, handle4 = \n",
    "# i = 1\n",
    "# for handle in np.array_split(handles, 16):\n",
    "#     handle.to_csv(f\"handle{i}.csv\", index=False)\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.datetime(2019, 5, 6)\n",
    "list_of_keys_user=[\n",
    "    \"id\",\"name\",\"screen_name\",\"location\",\"description\",\"followers_count\",\"friends_count\",\"statuses_count\",\"created_at\"\n",
    "]\n",
    "list_of_keys_tweet=[\n",
    "    \"created_at\",\"id\",\"lang\",\"full_text\",\n",
    "    \"retweeted\",\"retweeted_status\",\"retweet_count\",\n",
    "    \"is_quote_status\",\"quoted_status\",\"quote_count\",\n",
    "    \"entities\"\n",
    "]\n",
    "\n",
    "def limit_handled(cursor):\n",
    "    \"\"\"Generator to throttle scraping of Twitter-user timeline.\n",
    "    Yields next tweet in timeline\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            yield next(cursor)\n",
    "        except tweepy.RateLimitError as r: # If rate limit is reached sleep for 15 minutes\n",
    "            print(r.reason) \n",
    "            time.sleep(15 * 60)\n",
    "        except tweepy.TweepError as e: # If other error back off for 5 seconds, then continue\n",
    "            print(e.reason)\n",
    "            time.sleep(5)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "def get_all_tweets(handle):\n",
    "    \"\"\"Function is supposed to return all possible tweets from a user in a df\n",
    "    Handle is the handle of the account\"\"\"\n",
    "    timeline = tweepy.Cursor(api.user_timeline, screen_name=handle,\n",
    "                             tweet_mode=\"extended\",\n",
    "                             since=start_date)\n",
    "    tweet_list = [status._json for status in limit_handled(timeline.items())]\n",
    "    tweets=list()\n",
    "    for tweet in tweet_list:\n",
    "        for key in tweet:\n",
    "            temp_dict=dict()\n",
    "            for user_key in list_of_keys_user: # Access information on user \n",
    "                try:\n",
    "                    temp_dict[\"user_\"+user_key]=tweet[\"user\"][user_key]\n",
    "                except KeyError:\n",
    "                    temp_dict[\"user_\"+user_key]=None\n",
    "\n",
    "            for tweet_key in list_of_keys_tweet: # Access information on tweet\n",
    "                try: \n",
    "                    temp_dict[\"tweet_\"+tweet_key]=tweet[tweet_key]\n",
    "                except KeyError:\n",
    "                    temp_dict[\"tweet_\"+tweet_key]=None\n",
    "\n",
    "        tweets.append(temp_dict)\n",
    "    df = pd.DataFrame(tweets) \n",
    "    df = df.fillna(value=np.nan)\n",
    "    return df\n",
    "\n",
    "def get_tweets_from_handles(handlefile,print_handle=False):\n",
    "    \"\"\"Give this function the csv file with the handle \n",
    "    it returns a df including the tweets from all the handles\"\"\"\n",
    "    handles = pd.read_csv(handlefile)\n",
    "    handles=handles[\"Twitter Handle (uden @)\"].to_list()\n",
    "    df = pd.DataFrame()\n",
    "    for handle in tqdm(handles):\n",
    "        if print_handle:\n",
    "            print(handle)\n",
    "        temp = get_all_tweets(handle)\n",
    "        df = pd.concat([df, temp], ignore_index = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = tweepy.Cursor(api.user_timeline, screen_name=\"COWIdk\",\n",
    "                             tweet_mode=\"extended\",\n",
    "                             since=start_date)\n",
    "tweet_list = [status._json for status in limit_handled(timeline.items())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "handle5=get_tweets_from_handles(\"handle5.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
