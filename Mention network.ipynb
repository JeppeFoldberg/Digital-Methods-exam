{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import netwulf as nw\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset of tweets since election and list of our actors\n",
    "klima_df=pd.read_csv('climate_tweets_since_election.zip')\n",
    "df2=pd.read_excel('actor_list.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "klima_df=klima_df.drop_duplicates(subset='tweet_id')\n",
    "klima_df = klima_df.loc[df.tweet_created_at > '05-06-2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define extract functions\n",
    "def extract_list(string):\n",
    "    \"\"\"Helper function to extract dict from string if string exists \n",
    "    else the function returns an empty dict (Thanks, Tweepy...)\"\"\"\n",
    "    try:\n",
    "        out=ast.literal_eval(string)\n",
    "    except:\n",
    "        out=list()\n",
    "    return out\n",
    "\n",
    "\n",
    "def extract_dict(string):\n",
    "    \"\"\"Helper function to extract dict from string if string exists \n",
    "    else the function returns an empty dict (Thanks, Tweepy...)\"\"\"\n",
    "    try:\n",
    "        out=ast.literal_eval(string)\n",
    "    except:\n",
    "        out=dict()\n",
    "    return out\n",
    "\n",
    "def extract_from_entities(tweet,ent_key,tag_key):\n",
    "    \"\"\"Helper function to extract information from tweet_entities.\n",
    "    tweet_entities is a dict-of-dicts containing all information on \n",
    "    twitter entities from a given tweet.\n",
    "    ent_key: key used to access the dictionary of interest e.g. \"hastags\"\n",
    "    tag_key: key used to access value of interest e.g. \"text\"\n",
    "    Why, Tweepy? WHY?!\"\"\"\n",
    "    try:\n",
    "        out=[tag[tag_key] for tag in tweet[ent_key] if tweet[ent_key]!=ent_key]\n",
    "    except:\n",
    "        out=list()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract tweet entities dict into seperate columns\n",
    "\n",
    "klima_df[\"tweet_retweeted_status\"]=klima_df[\"tweet_retweeted_status\"].apply(lambda x:extract_dict(x))\n",
    "klima_df[\"tweet_quoted_status\"]=klima_df[\"tweet_quoted_status\"].apply(lambda x:extract_dict(x))\n",
    "klima_df[\"tweet_entities\"]=klima_df[\"tweet_entities\"].apply(lambda x:extract_dict(x))\n",
    "\n",
    "klima_df[\"tweet_hashtags\"]=klima_df.tweet_entities.apply(lambda tweet: extract_from_entities(tweet,\"hashtags\",\"text\"))\n",
    "klima_df[\"tweet_mentions\"]=klima_df.tweet_entities.apply(lambda tweet: extract_from_entities(tweet,\"user_mentions\",\"screen_name\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dict of accounts and who they mention\n",
    "mention_dict = defaultdict(list)\n",
    "for idx,row in klima_df.iterrows():\n",
    "    mention_dict[row['user_screen_name']].append(row['tweet_mentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only alphanumerical characters\n",
    "mention_dict2 = {key: value for key, value in mention_dict.items() if key.isalpha()}\n",
    "\n",
    "#flatten the lists in dict\n",
    "for key in mention_dict2.keys():\n",
    "    mention_dict2[key]=[item for sublist in mention_dict2[key] for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create network from dict\n",
    "mention_network=nx.from_dict_of_lists(mention_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of nodes that are not in our actor list\n",
    "not_rel=[]\n",
    "for i in list(mention_network.nodes()):\n",
    "    if i not in df2['actors'].to_list():\n",
    "        if i not in list(klima_df.user_screen_name.unique()):\n",
    "            if i not in df2['actors'].str.lower():\n",
    "                not_rel.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove \n",
    "for i in not_rel:\n",
    "    mention_network.remove_node(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
